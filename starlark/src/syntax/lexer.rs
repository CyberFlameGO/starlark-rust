/*
 * Copyright 2018 The Starlark in Rust Authors.
 * Copyright (c) Facebook, Inc. and its affiliates.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

use crate::{errors::Diagnostic, syntax::dialect::Dialect};
use codemap::{CodeMap, Span};
use std::{char, fmt, fmt::Display, sync::Arc};

/// Errors that can be generated during lexing
#[derive(Debug, Clone, PartialEq, Copy)]
pub enum LexerError {
    Indentation(u64, u64),
    InvalidCharacter(u64),
    InvalidTab(u64),
    UnfinishedStringLiteral(u64, u64),
    InvalidEscapeSequence(u64, u64),
    WrappedError { span: Span, message: &'static str },
}

impl LexerError {
    /// Convert the error to a codemap diagnostic.
    ///
    /// To build this diagnostic, the method needs the file span corresponding
    /// to the parsed file.
    pub(crate) fn add_span(self, span: Span, codemap: Arc<CodeMap>) -> Diagnostic {
        let span = match self {
            LexerError::Indentation(x, y)
            | LexerError::UnfinishedStringLiteral(x, y)
            | LexerError::InvalidEscapeSequence(x, y) => span.subspan(x, y),
            LexerError::InvalidTab(x) | LexerError::InvalidCharacter(x) => span.subspan(x, x),
            LexerError::WrappedError { span, .. } => span,
        };
        let mut e = Diagnostic::new(
            match self {
                LexerError::Indentation(..) => "Parse error: ncorrect indentation",
                LexerError::InvalidCharacter(..) => {
                    "Parse error: Character not valid at present location"
                }
                LexerError::UnfinishedStringLiteral(..) => "Parse error: unfinished string literal",
                LexerError::InvalidEscapeSequence(..) => {
                    "Parse error: invalid string escape sequence"
                }
                LexerError::InvalidTab(..) => "Parse error: tabs are not allowed in the dialect",
                LexerError::WrappedError { message, .. } => message,
            }
            .to_owned(),
        );
        e.set_span(span, codemap);
        e
    }
}

/// All token that can be generated by the lexer
#[derive(Debug, Clone, PartialEq)]
pub enum Token {
    // Indentation block & meaningfull spaces
    Indent,  // New indentation block
    Dedent,  // Leaving an indentation block
    Newline, // Newline outside a string
    // Keywords
    And,      // "and" keyword
    Else,     // "else" keyword
    Load,     // "load" keyword
    Break,    // "break" keyword
    For,      // "for" keyword
    Not,      // "not" keyword
    Continue, // "continue" keyword
    If,       // "if" keyword
    Or,       // "or" keyword
    Def,      // "def" keyword
    In,       // "in" keyword
    Pass,     // "pass" keyword
    Elif,     // "elif" keyword
    Return,   // "return" keyword
    Lambda,   // "lambda" keyword
    // Symbols
    Comma,            // ','
    Semicolon,        // ';'
    Colon,            // ':'
    PlusEqual,        // '+='
    MinusEqual,       // '-='
    StarEqual,        // '*='
    SlashEqual,       // '/='
    DoubleSlashEqual, // '//='
    PercentEqual,     // '%='
    DoubleEqual,      // '=='
    BangEqual,        // '!='
    LessEqual,        // '<='
    GreaterEqual,     // '>='
    DoubleStar,       // '**'
    RightArrow,       // '->'
    Equal,            // '='
    LessThan,         // '<'
    GreaterThan,      // '>'
    Minus,            // '-'
    Plus,             // '+'
    Star,             // '*'
    Percent,          // '%'
    Slash,            // '/'
    DoubleSlash,      // '//'
    Dot,              // '.'
    Pipe,             // '|'
    // Brackets
    OpeningSquare, // '['
    OpeningCurly,  // '{'
    OpeningRound,  // '('
    ClosingSquare, // ']'
    ClosingCurly,  // '}'
    ClosingRound,  // ')'

    Reserved(String),      // One of the reserved keywords
    Identifier(String),    // An identifier
    IntegerLiteral(i32),   // An integer literal (123, 0x1, 0b1011, 0o755, ...)
    StringLiteral(String), // A string literal
}

impl Display for Token {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Token::Indent => write!(f, "new indentation block"),
            Token::Dedent => write!(f, "end of indentation block"),
            Token::Newline => write!(f, "new line"),
            Token::And => write!(f, "keyword 'and'"),
            Token::Else => write!(f, "keyword 'else'"),
            Token::Load => write!(f, "keyword 'load'"),
            Token::Break => write!(f, "keyword 'break'"),
            Token::For => write!(f, "keyword 'for'"),
            Token::Not => write!(f, "keyword 'not'"),
            Token::Continue => write!(f, "keyword 'continue'"),
            Token::If => write!(f, "keyword 'if'"),
            Token::Or => write!(f, "keyword 'or'"),
            Token::Def => write!(f, "keyword 'def'"),
            Token::In => write!(f, "keyword 'in'"),
            Token::Pass => write!(f, "keyword 'pass'"),
            Token::Elif => write!(f, "keyword 'elif'"),
            Token::Return => write!(f, "keyword 'return'"),
            Token::Lambda => write!(f, "keyword 'lambda'"),
            Token::Comma => write!(f, "symbol ','"),
            Token::Semicolon => write!(f, "symbol ';'"),
            Token::Colon => write!(f, "symbol ':'"),
            Token::PlusEqual => write!(f, "symbol '+='"),
            Token::MinusEqual => write!(f, "symbol '-='"),
            Token::StarEqual => write!(f, "symbol '*='"),
            Token::SlashEqual => write!(f, "symbol '/='"),
            Token::DoubleSlashEqual => write!(f, "symbol '//='"),
            Token::PercentEqual => write!(f, "symbol '%='"),
            Token::DoubleEqual => write!(f, "symbol '=='"),
            Token::BangEqual => write!(f, "symbol '!='"),
            Token::LessEqual => write!(f, "symbol '<='"),
            Token::GreaterEqual => write!(f, "symbol '>='"),
            Token::DoubleStar => write!(f, "symbol '**'"),
            Token::RightArrow => write!(f, "symbol '->'"),
            Token::Equal => write!(f, "symbol '='"),
            Token::LessThan => write!(f, "symbol '<'"),
            Token::GreaterThan => write!(f, "symbol '>'"),
            Token::Minus => write!(f, "symbol '-'"),
            Token::Plus => write!(f, "symbol '+'"),
            Token::Star => write!(f, "symbol '*'"),
            Token::Percent => write!(f, "symbol '%'"),
            Token::Slash => write!(f, "symbol '/'"),
            Token::DoubleSlash => write!(f, "symbol '//'"),
            Token::Dot => write!(f, "symbol '.'"),
            Token::Pipe => write!(f, "symbol '|'"),
            Token::OpeningSquare => write!(f, "symbol '['"),
            Token::OpeningCurly => write!(f, "symbol '{{'"),
            Token::OpeningRound => write!(f, "symbol '('"),
            Token::ClosingSquare => write!(f, "symbol ']'"),
            Token::ClosingCurly => write!(f, "symbol '}}'"),
            Token::ClosingRound => write!(f, "symbol ')'"),
            Token::Reserved(s) => write!(f, "reserved keyword '{}'", s),
            Token::Identifier(s) => write!(f, "identifier '{}'", s),
            Token::IntegerLiteral(i) => write!(f, "integer literal '{}'", i),
            Token::StringLiteral(s) => write!(f, "string literal '{}'", s),
        }
    }
}

pub type LexerItem = Result<(u64, Token, u64), LexerError>;

/// An iterator over a string slice that convert it to a list of token, i.e. the
/// lexer.
#[derive(Debug)]
pub(crate) struct Lexer {
    input: String,
    /// Byte offset of the next char in `input`
    pos_bytes: usize,
    offset: u64,
    process_end_of_file: bool,
    last_new_line: bool,
    last_pos: u64,
    last_next: Option<(u64, char)>,
    indentation_stack: Vec<u32>,
    parentheses: i32,
    backlog: Vec<LexerItem>,
    enable_tabs: bool,
}

impl Lexer {
    /// Create a new lexer from a string slice
    pub fn new(input: &str, dialect: &Dialect) -> Self {
        let input = input.to_owned();
        Lexer {
            input,
            pos_bytes: 0,
            offset: 0,
            process_end_of_file: true,
            last_new_line: true,
            last_pos: 0,
            last_next: None,
            indentation_stack: Vec::new(),
            parentheses: 0,
            backlog: Vec::new(),
            enable_tabs: dialect.enable_tabs,
        }
    }

    /// Enqueue a
    fn is_nl(c: char) -> bool {
        match c {
            '\n' | '\r' | '\u{2028}' | '\u{2029}' => true,
            _ => false,
        }
    }

    fn peek(&mut self) -> Option<(u64, char)> {
        match self.input[self.pos_bytes..].chars().next() {
            Some(c) => Some((self.pos_bytes as u64 + self.offset, c)),
            None => None,
        }
    }

    fn pop(&mut self) -> Option<(u64, char)> {
        let mut char_indices = self.input[self.pos_bytes..].char_indices();
        self.last_next = match char_indices.next() {
            Some((_, c)) => {
                let pos = self.pos_bytes;
                self.pos_bytes = match char_indices.next() {
                    Some((len, _)) => self.pos_bytes + len,
                    None => self.input.len(),
                };
                self.last_new_line = Lexer::is_nl(c);
                Some((pos as u64 + self.offset, c))
            }
            None => {
                self.last_new_line = false;
                None
            }
        };
        self.last_next
    }

    fn terminate(&mut self) {
        self.pos_bytes = self.input.len();
        self.indentation_stack.clear();
        self.parentheses = 0;
    }

    fn next_char(&mut self) -> char {
        self.pop().unwrap_or((0, '\0')).1
    }

    fn peek_char(&mut self) -> char {
        self.peek().unwrap_or((0, '\0')).1
    }

    fn return_none(&mut self) -> Option<LexerItem> {
        // Emit a newline and N DEDENT at EOF
        let p = self.end_pos();
        if !self.last_new_line {
            self.last_new_line = true;
            Some(Ok((p.1, Token::Newline, p.1)))
        } else if self.ihead() > 0 && self.process_end_of_file {
            self.indentation_stack.pop();
            Some(Ok((p.1, Token::Dedent, p.1)))
        } else {
            None
        }
    }

    fn ihead(&self) -> u32 {
        *self.indentation_stack.last().unwrap_or(&0)
    }

    fn begin(&mut self) {
        if let Some((i, ..)) = self.peek() {
            self.last_pos = i;
        }
    }

    fn end_pos(&mut self) -> (u64, u64) {
        if let Some((end, ..)) = self.peek() {
            (self.last_pos, end)
        } else if let Some((i, c)) = self.last_next {
            (self.last_pos, i + (c.len_utf8() as u64))
        } else {
            (self.last_pos, self.last_pos)
        }
    }

    fn end(&mut self, res: Token) -> Option<LexerItem> {
        let p = self.end_pos();
        assert!(p.0 <= p.1, "{} > {}", p.0, p.1);
        Some(Ok((p.0, res, p.1)))
    }

    fn consume(&mut self, res: Token) -> Option<LexerItem> {
        self.pop();
        self.end(res)
    }

    fn invalid(&mut self) -> Option<LexerItem> {
        let p = self.end_pos();
        Some(Err(LexerError::InvalidCharacter(p.1)))
    }

    fn internal_next(&mut self) -> Option<LexerItem> {
        if !self.backlog.is_empty() {
            return self.backlog.pop();
        }
        if self.peek().is_none() {
            return self.return_none();
        }
        let r = self.consume_token();
        if let Some(Err(_)) = r {
            // In case of errors, consume the whole input so we stop on next call
            self.terminate();
        } else if r.is_none() {
            return self.return_none();
        }
        r
    }
}

impl Iterator for Lexer {
    type Item = LexerItem;

    fn next(&mut self) -> Option<Self::Item> {
        self.internal_next()
    }
}

// Consumers to actually consume token
impl Lexer {
    fn token_from_identifier(identifier: &str) -> Token {
        match identifier {
            "and" => Token::And,
            "else" => Token::Else,
            "load" => Token::Load,
            "break" => Token::Break,
            "for" => Token::For,
            "not" => Token::Not,
            "continue" => Token::Continue,
            "if" => Token::If,
            "or" => Token::Or,
            "def" => Token::Def,
            "in" => Token::In,
            "pass" => Token::Pass,
            "elif" => Token::Elif,
            "return" => Token::Return,
            "lambda" => Token::Lambda,
            "as" | "import" | "is" | "class" | "nonlocal" | "del" | "raise" | "except" | "try"
            | "finally" | "while" | "from" | "with" | "global" | "yield" => {
                Token::Reserved(identifier.to_owned())
            }
            _ => Token::Identifier(identifier.to_owned()),
        }
    }

    fn skip_comment(&mut self) {
        assert_eq!(self.next_char(), '#');
        loop {
            match self.peek_char() {
                '\n' | '\r' | '\u{2028}' | '\u{2029}' | '\0' => return,
                _ => {
                    self.pop();
                }
            }
        }
    }

    fn skip_spaces(&mut self, newline: bool) -> Option<LexerItem> {
        loop {
            match self.peek_char() {
                '\n' | '\r' | '\u{2028}' | '\u{2029}' => {
                    if newline {
                        self.pop();
                    } else {
                        return None;
                    }
                }
                '\\' => {
                    self.pop();
                    if self.peek_char() != '\n' {
                        return self.invalid();
                    } else {
                        self.pop();
                    }
                }
                ' ' => {
                    self.pop();
                }
                '\t' => {
                    if self.enable_tabs {
                        self.pop();
                    } else {
                        return Some(Err(LexerError::InvalidTab(self.end_pos().1)));
                    }
                }
                '#' => self.skip_comment(),
                _ => return None,
            };
        }
    }

    fn consume_spaces(&mut self) -> Result<u32, LexerError> {
        let mut result = 0;
        loop {
            match self.peek_char() {
                '\t' => {
                    if !self.enable_tabs {
                        return Err(LexerError::InvalidTab(self.end_pos().1));
                    }
                    result += 8 - (result % 8);
                }
                ' ' => result += 1,
                _ => return Ok(result),
            };
            self.pop();
        }
    }

    fn consume_indentation(&mut self) -> Option<LexerItem> {
        loop {
            self.begin();
            let spaces = match self.consume_spaces() {
                Ok(spaces) => spaces,
                Err(e) => {
                    return Some(Err(e));
                }
            };
            let p = self.peek_char();
            if Lexer::is_nl(p) {
                // ignore because it is an empty line, but still return new line
                return None;
            } else if p == '#' {
                // Ignore the comment and start again
                self.skip_comment();
                self.consume_nl();
                continue;
            } else if spaces > self.ihead() {
                self.indentation_stack.push(spaces);
                return self.end(Token::Indent);
            } else if spaces == self.ihead() {
                return None;
            } else {
                let mut step = 0;
                while spaces < self.ihead() {
                    self.indentation_stack.pop();
                    step += 1;
                }
                if spaces == self.ihead() {
                    let r = self.end(Token::Dedent);
                    while step > 1 {
                        self.backlog.push(r.clone().unwrap());
                        step -= 1;
                    }
                    return r;
                } else {
                    let p = self.end_pos();
                    return Some(Err(LexerError::Indentation(p.0, p.1)));
                }
            }
        }
    }

    fn consume_nl(&mut self) -> Option<LexerItem> {
        self.begin();
        match (self.next_char(), self.peek_char()) {
            ('\n', '\r') | ('\r', '\n') => self.consume(Token::Newline),
            _ => self.end(Token::Newline),
        }
    }

    fn consume_identifier_queue(&mut self, head: &str) -> Option<LexerItem> {
        let mut result = head.to_owned();
        while self.peek_char().is_alphabetic()
            || self.peek_char().is_digit(10)
            || self.peek_char() == '_'
        {
            result.push(self.next_char());
        }
        assert!(!result.is_empty());
        self.end(Self::token_from_identifier(&result))
    }

    fn consume_identifier(&mut self) -> Option<LexerItem> {
        self.begin();
        assert!(!self.peek_char().is_digit(10));
        self.consume_identifier_queue("")
    }

    fn consume_int_r(&mut self, radix: u32) -> Result<i32, ()> {
        let mut number = String::new();
        while self.peek_char().is_digit(radix) {
            number.push(self.next_char());
        }
        let val = i32::from_str_radix(&number, radix);
        match val {
            Err(_) => Err(()),
            Ok(v) => Ok(v),
        }
    }

    fn consume_int_radix(&mut self, radix: u32) -> Option<LexerItem> {
        let val = self.consume_int_r(radix);
        match val {
            Err(_) => self.invalid(),
            Ok(v) => self.end(Token::IntegerLiteral(v)),
        }
    }

    fn consume_int(&mut self) -> Option<LexerItem> {
        self.begin();
        let cur = self.peek_char();
        if cur == '0' {
            self.pop();
            let cur = self.peek_char();
            match cur {
                'o' | 'O' => {
                    self.pop();
                    self.consume_int_radix(8)
                }
                'x' | 'X' => {
                    self.pop();
                    self.consume_int_radix(16)
                }
                'b' | 'B' => {
                    self.pop();
                    self.consume_int_radix(2)
                }
                c if !c.is_numeric() => self.end(Token::IntegerLiteral(0)),
                _ => self.invalid(),
            }
        } else {
            self.consume_int_radix(10)
        }
    }

    fn consume_escape_sequence(&mut self, _triple: bool) -> Result<Option<char>, LexerError> {
        if let Some((pos, c)) = self.pop() {
            assert_eq!(c, '\\');
            if let Some((pos2, c2)) = self.peek() {
                match c2 {
                    'n' => {
                        self.pop();
                        Ok(Some('\n'))
                    }
                    'r' => {
                        self.pop();
                        Ok(Some('\r'))
                    }
                    't' => {
                        self.pop();
                        Ok(Some('\t'))
                    }
                    '0' => {
                        self.pop();
                        if self.peek_char().is_digit(8) {
                            if let Ok(r) = self.consume_int_r(8) {
                                Ok(Some(char::from_u32(r as u32).unwrap()))
                            } else {
                                let p = self.end_pos();
                                Err(LexerError::InvalidEscapeSequence(pos, p.1))
                            }
                        } else {
                            Ok(Some('\0'))
                        }
                    }
                    'x' => {
                        self.pop();
                        if let Ok(r) = self.consume_int_r(16) {
                            Ok(Some(char::from_u32(r as u32).unwrap()))
                        } else {
                            let p = self.end_pos();
                            Err(LexerError::InvalidEscapeSequence(pos, p.1))
                        }
                    }
                    '1'..='9' => {
                        self.pop();
                        Err(LexerError::InvalidEscapeSequence(pos, pos2 + 1))
                    }
                    '\n' => {
                        self.pop();
                        // if triple {
                        Ok(None)
                        /*
                        } else {
                            Err(LexerError::InvalidEscapeSequence(pos, pos2 + 1))
                        }*/
                    }
                    'u' => {
                        self.pop();
                        let c = self.next_char();
                        if c != '{' {
                            let p = self.end_pos();
                            Err(LexerError::InvalidEscapeSequence(pos, p.1))
                        } else if let Ok(r) = self.consume_int_r(16) {
                            let c = self.next_char();
                            if c != '}' {
                                let p = self.end_pos();
                                Err(LexerError::InvalidEscapeSequence(pos, p.1))
                            } else {
                                Ok(Some(char::from_u32(r as u32).unwrap()))
                            }
                        } else {
                            let p = self.end_pos();
                            Err(LexerError::InvalidEscapeSequence(pos, p.1))
                        }
                    }
                    '"' | '\'' | '\\' => {
                        self.pop();
                        Ok(Some(c2))
                    }
                    _ => Ok(Some('\\')),
                }
            } else {
                Err(LexerError::InvalidEscapeSequence(pos, pos + 1))
            }
        } else {
            panic!("This is a bug");
        }
    }

    fn consume_string(&mut self, raw: bool) -> Option<LexerItem> {
        self.begin();
        let mut res = String::new();
        let quote = self.next_char();
        let mut triple = false;
        if self.peek_char() == quote {
            self.next_char();
            if self.peek_char() == quote {
                self.next_char();
                triple = true;
            } else {
                return self.end(Token::StringLiteral(res));
            }
        }
        loop {
            match self.peek_char() {
                '\\' => {
                    if raw {
                        self.pop();
                        if self.peek_char() == quote {
                            self.pop();
                            res.push(quote);
                        } else {
                            res.push('\\');
                        }
                    } else {
                        match self.consume_escape_sequence(triple) {
                            Ok(Some(x)) => res.push(x),
                            Ok(None) => {}
                            Err(c) => return Some(Err(c)),
                        }
                    }
                }
                '\n' | '\r' | '\u{2028}' | '\u{2029}' => {
                    if triple {
                        res.push(self.next_char());
                    } else {
                        let p = self.end_pos();
                        return Some(Err(LexerError::UnfinishedStringLiteral(p.0, p.1)));
                    }
                }
                '\0' => {
                    let p = self.end_pos();
                    return Some(Err(LexerError::UnfinishedStringLiteral(p.0, p.1)));
                }
                x if x == quote => {
                    self.pop();
                    if triple {
                        if self.peek_char() == quote {
                            self.pop();
                            if self.peek_char() == quote {
                                self.pop();
                                break;
                            } else {
                                res.push(quote);
                                res.push(quote);
                            }
                        } else {
                            res.push(quote);
                        }
                    } else {
                        break;
                    }
                }
                x => {
                    self.pop();
                    res.push(x);
                }
            }
        }
        self.end(Token::StringLiteral(res))
    }

    fn consume_token(&mut self) -> Option<LexerItem> {
        if self.last_new_line && self.parentheses == 0 {
            if let Some(r) = self.consume_indentation() {
                return Some(r);
            }
        } else {
            let skip_newline = self.parentheses > 0;
            if let Some(x) = self.skip_spaces(skip_newline) {
                return Some(x);
            }
        }
        self.begin();
        match self.peek_char() {
            '\0' => None,
            '\n' | '\r' | '\u{2028}' | '\u{2029}' => self.consume_nl(),
            '\'' | '"' => self.consume_string(false),
            'r' => {
                self.pop();
                let p = self.peek_char();
                if p == '\'' || p == '"' {
                    self.consume_string(true)
                } else {
                    self.consume_identifier_queue("r")
                }
            }
            '0'..='9' => self.consume_int(),
            '_' => self.consume_identifier(),
            c if c.is_alphabetic() => self.consume_identifier(),
            ',' => self.consume(Token::Comma),
            ';' => self.consume(Token::Semicolon),
            ':' => self.consume(Token::Colon),
            '+' => {
                self.pop();
                if self.peek_char() == '=' {
                    self.consume(Token::PlusEqual)
                } else {
                    self.end(Token::Plus)
                }
            }
            '-' => {
                self.pop();
                match self.peek_char() {
                    '=' => self.consume(Token::MinusEqual),
                    '>' => self.consume(Token::RightArrow),
                    _ => self.end(Token::Minus),
                }
            }
            '*' => {
                self.pop();
                match self.peek_char() {
                    '=' => self.consume(Token::StarEqual),
                    '*' => self.consume(Token::DoubleStar),
                    _ => self.end(Token::Star),
                }
            }
            '/' => {
                self.pop();
                if self.peek_char() == '=' {
                    self.consume(Token::SlashEqual)
                } else if self.peek_char() == '/' {
                    self.pop();
                    if self.peek_char() == '=' {
                        self.consume(Token::DoubleSlashEqual)
                    } else {
                        self.end(Token::DoubleSlash)
                    }
                } else {
                    self.end(Token::Slash)
                }
            }
            '%' => {
                self.pop();
                if self.peek_char() == '=' {
                    self.consume(Token::PercentEqual)
                } else {
                    self.end(Token::Percent)
                }
            }
            '=' => {
                self.pop();
                if self.peek_char() == '=' {
                    self.consume(Token::DoubleEqual)
                } else {
                    self.end(Token::Equal)
                }
            }
            '!' => {
                self.pop();
                if self.peek_char() == '=' {
                    self.consume(Token::BangEqual)
                } else {
                    self.invalid()
                }
            }
            '<' => {
                self.pop();
                if self.peek_char() == '=' {
                    self.consume(Token::LessEqual)
                } else {
                    self.end(Token::LessThan)
                }
            }
            '>' => {
                self.pop();
                if self.peek_char() == '=' {
                    self.consume(Token::GreaterEqual)
                } else {
                    self.end(Token::GreaterThan)
                }
            }
            '|' => self.consume(Token::Pipe),
            '.' => self.consume(Token::Dot),
            '[' => {
                self.parentheses += 1;
                self.consume(Token::OpeningSquare)
            }
            ']' => {
                self.parentheses -= 1;
                self.consume(Token::ClosingSquare)
            }
            '(' => {
                self.parentheses += 1;
                self.consume(Token::OpeningRound)
            }
            ')' => {
                self.parentheses -= 1;
                self.consume(Token::ClosingRound)
            }
            '{' => {
                self.parentheses += 1;
                self.consume(Token::OpeningCurly)
            }
            '}' => {
                self.parentheses -= 1;
                self.consume(Token::ClosingCurly)
            }
            _ => self.invalid(),
        }
    }
}
